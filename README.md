# SuperCLUE-Safety
# A Comprehensive Security Benchmark with SuperCLUE

SuperCLUE-Safety综合性安全基准

# 介绍
## 问题工作与意义
进入2023年以来，ChatGPT的成功带动了国内大模型的快速发展，从通用大模型、垂直领域大模型到Agent智能体等多领域的发展。
但是生成式大模型生成内容具有一定的不可控性，输出的内容并不总是可靠、安全和负责任的。比如当用户不良诱导或恶意输入的时候，
模型可能产生一些不合适的内容，甚至是价值观倾向错误的内容。这些都限制了大模型应用的普及以及大模型的广泛部署。
随着国内生成式人工智能快速发展，相关监管政策也逐步落实。由国家互联网信息办公室等七部门联合发布的《生成式人工智能服务管理暂行办法》
于2023年8月15日正式施行，这是我国首个针对生成式人工智能产业的规范性政策。制度的出台不仅仅是规范其发展，更是良性引导和鼓励创新。
安全和负责任的大模型必要性进一步提升。市场上已经存在部分安全类的基准测试，但是这些基准存在三方面的问题：

#### 1）问题挑战性低
     
     当前的模型可以轻松完成挑战。比如很多模型达到了95%以上的准确率；

#### 2）限于单轮测试
     
     无法全面衡量在多轮交互场景下模型的安全防护能力；

#### 3）衡量维度覆盖面窄
     
     没有全面衡量大模型的安全防护能力，经常仅限于传统安全类问题；

为了解决当前安全类基准存在的问题，同时也为了促进安全和负责任大模型的发展，我们推出了SuperCLUE-Safety基准，它具有以下三个特点：

#### 1）具有较高的挑战性
      
      通过模型和人类的对抗性技术的引入，大幅提升问题的难度；也更识别除模型在各类不良诱导或恶意输入下的安全防护能力。

#### 2）多轮交互下安全能力测试
      
       不仅具有单轮测试，还同时支持多轮测试。能测试大模型在多轮交互场景下安全防护能力，更接近真实用户下的场景。

#### 3）全面衡量大模型安全防护能力
       
       除了传统安全类问题，还包括负责任人工智能、指令攻击等新型和更高阶的能力要求。

## 介绍

## 特点

# 体系
## 能力评估与维度
## 能力评估与维度图
## 能力定义
## 示例

# 实验

## 模型与榜单
TODO 需要一些数据

## 人类一致性评估

TODO 需要一些数据

## 单轮vs多轮
TODO 需要一些数据

## 实验发现(分享)

# 使用

# 阅读材料及引用

