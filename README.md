# SuperCLUE-Safety：中文大模型综合性安全基准
### A Comprehensive Security Benchmark with SuperCLUE

# 介绍
进入2023年以来，ChatGPT的成功带动了国内大模型的快速发展，从通用大模型、垂直领域大模型到Agent智能体等多领域的发展。
但是生成式大模型生成内容具有一定的不可控性，输出的内容并不总是可靠、安全和负责任的。比如当用户不良诱导或恶意输入的时候，
模型可能产生一些不合适的内容，甚至是价值观倾向错误的内容。这些都限制了大模型应用的普及以及大模型的广泛部署。

随着国内生成式人工智能快速发展，相关监管政策也逐步落实。由国家互联网信息办公室等七部门联合发布的《生成式人工智能服务管理暂行办法》
于2023年8月15日正式施行，这是我国首个针对生成式人工智能产业的规范性政策。制度的出台不仅仅是规范其发展，更是良性引导和鼓励创新。
安全和负责任的大模型必要性进一步提升。国内已经存在部分安全类的基准测试，但当前这些基准存在三方面的问题：

#### 1）问题挑战性低
     
  当前的模型大多可以轻松完成挑战，比如很多模型在这些基准上的准确率达到了95%以上的准确率；

#### 2）限于单轮测试
     
  没有考虑多轮问题，无法全面衡量在多轮交互场景下模型的安全防护能力；

#### 3）衡量维度覆盖面窄
     
  没有全面衡量大模型的安全防护能力，经常仅限于传统安全类问题（如辱骂、违法犯罪、隐私、身心健康等）；

为了解决当前安全类基准存在的问题，同时也为了促进安全和负责任中文大模型的发展，我们推出了SuperCLUE-Safety基准，它具有以下三个特点：

#### 1）具有较高的挑战性

  通过模型和人类的迭代式对抗性技术的引入，大幅提升安全类问题的挑战性；可以更好的识别出模型在各类不良诱导、恶意输入和广泛领域下的安全防护能力。

#### 2）多轮交互下安全能力测试
      
 不仅支持单轮测试，还同时支持多轮场景测试。能测试大模型在多轮交互场景下安全防护能力，更接近真实用户下的场景。

#### 3）全面衡量大模型安全防护能力
       
   除了传统安全类问题，还包括负责任人工智能、指令攻击等新型和更高阶的能力要求。


# SC-Safety体系（能力、定义、图和示例）
## 能力评估与维度

SC-Safety大模型安全类测评包含以下三大能力的检验：传统安全类、负责任人工智能和指令攻击。

以下是对这三个领域的定义：

#### 传统安全类：

这是AI大模型安全的基本要求，它关注模型是否能够遵守基本的道德和法律标准。这包括，但不限于避免生成辱骂、违法犯罪的内容，尊重隐私
以及维护身心健康等。在此类下的测评，模型需要展示出它能够理解和遵守这些基本的安全和伦理标准。

#### 负责任人工智能：

这是一个更高阶的要求，它不仅关注AI模型是否遵守基本的道德和法律标准，还关注模型是否能与人类价值观对齐。这包括，但不限于，对环境的友好，
对弱势群体友好以及其他更广泛的社会责任。在此类下的测评，模型需要展示出它能够理解和尊重这些更高阶的价值观，并能在输出中体现这些价值观。

#### 指令攻击：

这是一种新兴的安全威胁，它关注的是是否有可能通过特定的提示词或输入来绕过模型的现有安全防护，引导模型生成不良或有害的输出。这类攻击包括
但不限于，误导性的提示、潜在的恶意指令，或者其他试图利用模型的弱点的尝试。在此类下的测评，模型需要展示出它能够有效地识别并抵御这些潜在的攻击。

这三个领域共同构成了一个全面的AI大模型的安全类测评体系，能够检验模型在遵守基本道德法律标准、与人类价值观的对齐，以及抵御潜在攻击等方面的能力。


## 能力评估与维度图

## 能力定义
传统安全类

负责任人工智能

指令攻击

## 示例

# 实验

## 模型与榜单
TODO 需要一些数据

## 人类一致性评估

TODO 需要一些数据

## 单轮vs多轮
TODO 需要一些数据

## 实验发现(分享)

# 使用

# 阅读材料及引用

